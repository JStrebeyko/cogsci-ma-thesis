{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## literatura\n",
    "kwerenda literatury jeśli chodzi o polskie llmy, czy międzynarodowe\n",
    "preferujemy otwarte, kwestia licencji\n",
    "różne wielkości\n",
    "- jest od Piotra wniosek o Cluster\n",
    "\n",
    "specyfika polskiego, analiza porównawcza, cechy składniowe maszyna vs człowiek\n",
    "- złożoność drzew składniowych\n",
    "- powtarzalność\n",
    "- szyk\n",
    "- ...\n",
    "- ngram-y do analizy cross-author\n",
    "\n",
    "-> sprawdzić jasnopis\n",
    "\n",
    "Polskie llmy\n",
    "- podsumowanie polskich vs chat\n",
    "- czy są dostrajane, jakie są rozmiary\n",
    "\n",
    "\n",
    "utajnić.\n",
    "\n",
    "czy użytkowenicy i którzy używają zbiorów treningowych? tylko tym udostępnić\n",
    "\n",
    "do pracy magisterskiej\n",
    "1.przegląd poprzednich korpusów i wydarzeń sharetasków\n",
    "2. analiza korpusowa porównawcza korpusowa\n",
    "\n",
    "-> część obowiązkowa\n",
    "- rozpoznawanie zbioru danych do zadania\n",
    "- otwarta licencja\n",
    "- teksty napisane przez ludzi i przez maszynę\n",
    "- analiza korpusowa, choćby minimalna - właściwości tych testów, długość słów, porównanie cechy stylometryczne\n",
    "\n",
    "-> część opcjonalna\n",
    "- bardziej naukowa\n",
    "- nie wiadomo, kiedy (poleval wciąż w konstrukcji)\n",
    "\n",
    "\n",
    "pomysły \"hiszpańskie\",\n",
    "realizowane tam na konferencji z tym samym zadaniem\n",
    "-> język nieangielski, wygenerować teskty a potem shared task do rozpoznawania tych tekstów\n",
    "\n",
    "\n",
    "technicznie\n",
    "- inna stażystka, kończy działanie przeszukania HG dla polskiego zbioru zadania. podobno zrobiła wstępny research\n",
    "- musi być dataset używający lincejcji \"koszernej\" - zacznijmy od tekstów za otwartej licencji\n",
    "\n",
    "zaczynamy od tekstów oryginalny, połowa z nich zostaje\n",
    "\n",
    "bierzemy poczatek tekstu oryginalnego i dogenerowujemy resztę, często z jakimś pre-promptem\n",
    "- uniknąć łatwych rozróżnień w długości, ucięte w połowie słowa -> lub uciąć tekst człowieka napisane\n",
    "- rola\n",
    "\n",
    "wykorzystać dużo różnych `gatunków`, 5,6 gatunków\n",
    "- recencje\n",
    "- wikipedia\n",
    "- newsowe\n",
    "\n",
    "\n",
    "co z tego typu zadań, było robione?\n",
    "dla angielskiego jest sporo, przegląd literatury\n",
    "\n",
    "\n",
    "\n",
    "tekstów: kilkadziesiąt tysięcy, solidne testowe i treningowe\n",
    "- cześć gatunków tylko w danych testowych by zobaczyć \"odporność na dziedzinę\", np \"newsy\" tylko w testowych\n",
    "\n",
    "\n",
    "\n",
    "Ryzyko:\n",
    "testy zbyt proste\n",
    "jeśli są zbyt trudne, to super :D\n",
    "\n",
    "\n",
    "terminy:  poleval pod koniec roku\n",
    "-> mamy czas! jakość jest najważniejsza\n",
    "\n",
    "https://gitlab.com/FilipStefaniuk/hatespeech\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
