- [ ] check "llms for bias detection research" - and pick three papers

# Wikipedia

## NPOV

- [ ] [Is the Wikipedia Neutral?](https://reagle.org/joseph/2005/06/neutrality.html)

## LLMs, NPOV

- [x] ⭐ ~[Seeing Like an AI: How LLMs Apply (and Misapply) Wikipedia Neutrality Norms](https://arxiv.org/abs/2407.04183)~

## AI

- [ ] [Research:Large Language Models (LLMs) Impact on Wikipedia's Sustainability](<https://meta.wikimedia.org/wiki/Research:Large_Language_Models_(LLMs)_Impact_on_Wikipedia%27s_Sustainability>)
- [ ] [Wikimedia data for AI: a review of Wikimedia datasets for NLP tasks and AI-assisted editing](https://arxiv.org/abs/2410.08918)
- [ ] [ORES: Lowering Barriers with Participatory Machine Learning in Wikipedia](https://arxiv.org/abs/1909.05189)
- [ ] [Objective Revision Evaluation Service/damaging in Polish Wiki scores](<https://meta.wikimedia.org/wiki/Objective_Revision_Evaluation_Service/damaging#Polish_Wikipedia_(plwiki)>), see [the model in Left Wing as well](https://analytics.wikimedia.org/published/wmf-ml-models/damaging/plwiki/20220214171806/)
- [ ] ["Tell Me More" paper](https://grouplens.org/site-content/uploads/2013/09/wikisym2013_warnckewang-cosley-riedl.pdf) on article quality assessing model.

## edits

- [ ] [edit wars](https://en.wikipedia.org/wiki/Wikipedia:Edit_warring#The_three-revert_rule)
- [ ] [anti-vandalism unit](https://en.wikipedia.org/wiki/Wikipedia:Counter-Vandalism_Unit)
- [ ] [Research:Learning from dispute templates](https://meta.wikimedia.org/wiki/Research:Learning_from_dispute_templates)

## abuse detection

- [ ] [Research:Wikipedia Knowledge Integrity Risk Observatory](https://meta.wikimedia.org/wiki/Research:Wikipedia_Knowledge_Integrity_Risk_Observatory)
- [ ] [Research:Understanding hoax articles on English Wikipedia](https://meta.wikimedia.org/wiki/Research:Understanding_hoax_articles_on_English_Wikipedia)
- [ ] [Research:Sockpuppet detection in Wikimedia projects/Formative research](https://meta.wikimedia.org/wiki/Research:Sockpuppet_detection_in_Wikimedia_projects/Formative_research#Short_literature_review)
- [ ] [Research:Automated classification of edit quality](https://meta.wikimedia.org/wiki/Research:Automated_classification_of_edit_quality). Note, that the model for vandalism detection works by
  > drawing lightly from contextual features of an edit and heavily from the characteristics of the user making the edit.

making a situation more difficult to newcomers.

- [ ] [Research:Detox](https://meta.wikimedia.org/wiki/Research:Detox), which at aims at aggressive behavior detection. Could be indicative disinformation initiative, yet yet again is a method based on users and not the content itself. See also the paper: [Ex Machina: Personal Attacks Seen at Scale](https://arxiv.org/abs/1610.08914)

## research

- [ ] [Research:Exploration on content propagation across Wikimedia projects](https://meta.wikimedia.org/wiki/Research:Exploration_on_content_propagation_across_Wikimedia_projects)

## croatian case

- [ ] [RfC](https://meta.wikimedia.org/wiki/Requests_for_comment/Site-wide_administrator_abuse_and_WP:PILLARS_violations_on_the_Croatian_Wikipedia)

## wikipedia misc

- [ ] [users _are_ seeking mediacal advice](https://meta.wikimedia.org/wiki/Research:Investigating_Wikipedia%27s_role_as_a_gateway_to_medical_content)

# NLP

## General, PL, evaluations

- [] [awesome nlp pl](https://github.com/ksopyla/awesome-nlp-polish?tab=readme-ov-file)

## model evaluation

- [] [The LLM Evaluation guidebook ⚖️](https://github.com/huggingface/evaluation-guidebook)

## Tools

- [] [Word2vec](https://en.wikipedia.org/wiki/Word2vec)

## knowledge graphs

- [] [An Introduction to Knowledge Graphs](https://ai.stanford.edu/blog/introduction-to-knowledge-graphs/)
- [] [Wikinformetrics: Construction and description of an open Wikipedia knowledge graph data set for informetric purposes](https://direct.mit.edu/qss/article-pdf/3/4/931/2070779/qss_a_00226.pdf)
- [] [WikiKnowledgeGraphs](https://github.com/nateburley/WikiKnowledgeGraphs)
- [] [Comparative Analysis of Knowledge Graphs Constructed from Fake News and Legitimate News Sources](https://wikiworkshop.org/papers/comparative-analysis-of-knowledge-graphs-constructed-from-fake-news-and-legitimate-news-sources.pdf)

## temporal network analysis

- [] [Temporal network analysis: Introduction, methods and detailed tutorial with R](https://arxiv.org/pdf/2307.12339)

## bias detection

- [] ⭐ [Automatically Neutralizing Subjective Bias in Text](https://arxiv.org/pdf/1911.09709)
- [] [Automated identification of media bias in news articles: an interdisciplinary literature review](https://link.springer.com/article/10.1007/s00799-018-0261-y)
- [] [An Interdisciplinary Approach for the Automated Detection and Visualization of Media Bias in News Articles](https://arxiv.org/pdf/2112.13352)

## sentiment analysis in PL

- [] [Multi-Level Sentiment Analysis of PolEmo 2.0: Extended Corpus of Multi-Domain Consumer Reviews](https://aclanthology.org/K19-1092.pdf)

### non-credible sources

- [] [ERINIA: Evaluating the Robustness of Non-Credible Text Identification by Anticipating Adversarial Actions](https://ceur-ws.org/Vol-3525/paper5.pdf)

## Information Gaps

- [] [Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia](https://arxiv.org/pdf/2410.04282) \ [Github](https://github.com/smfsamir/infogap)

## stance detection

- [] ⭐ [Stance Detection on Social Media: State of the Art and Trends](https://arxiv.org/pdf/2006.03644) - siminlgy good intro
- [] ⭐ [Stance detection: a practical guide to classifying political beliefs in text](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/E227E746BD7D9751526DA0EC2C378787/S2049847024000359a.pdf/stance-detection-a-practical-guide-to-classifying-political-beliefs-in-text.pdf)

- [] [Infusing Knowledge from Wikipedia to Enhance Stance Detection](https://arxiv.org/pdf/2204.03839v1)

## metrics

### persuation

- [Overview of the CLEF-2024 CheckThat! Lab: Check-Worthiness, Subjectivity, Persuasion, Roles, Authorities, and Adversarial Robustness](https://link.springer.com/chapter/10.1007/978-3-031-71908-0_2)

### moral judgement alignment

- [MoCa: Measuring Human-Language Model Alignment on Causal and Moral Judgment Tasks](https://web.stanford.edu/~cpiech/bio/papers/moca.pdf)

### desinformation

- [Jigsaw's The Current: Disinformation](https://current.withgoogle.com/the-current/disinformation/) (seek _references_, _theories_, _events_)

## others

- [ ] [The Prompt Report: A Systematic Survey of Prompting Techniques](https://arxiv.org/pdf/2406.06608)
- [ ] [Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition](https://arxiv.org/abs/2311.16119)
- [ ] [Attention Heads of Large Language Models: A Survey](https://arxiv.org/pdf/2409.03752)
- [ ] [The Llama 3 Herd of Models](https://arxiv.org/pdf/2407.21783)
- [ ] [System Design for Recommendations and Search // Eugene Yan // MLOps Meetup #78](https://www.youtube.com/watch?v=lh9CNRDqKBk)
- [ ] [Fact, Fetch, and Reason: A Unified Evaluation of Retrieval-Augmented Generation](https://arxiv.org/abs/2409.12941)
