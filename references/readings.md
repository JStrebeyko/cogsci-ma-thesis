### The Case of Croatian Wikipedia: Encyclopaedia of Knowledge or Encyclopaedia for the Nation?

> This report represents the evaluation of the Croatian disinformation case by an external expert on the subject matter,

> (...) Serbo-Croatian Wikipedia’s community was split up into Croatian, Bosnian, Serbian, and the original Serbo-Croatian wikis starting in 2003. The report concludes that this structure enabled local language communities to sort by points of view on each project, often falling along political party lines in the respective regions.

> a group of administrators and editors have held de-facto control over the project for more than a decade.

> During that time, evidence that he evaluated suggests that they have intentionally distorted the content presented in articles, abused power, and systematically obstructed otherwise accepted global Wikipedia community practices.

> the group leaders who were primarily responsible for abusing the project through sock-puppeting.

> proven that a core member of the group was obstructing community voting procedures through "sock-puppets", a highly manipulative practice of creating and using inauthentic online identities for the purpose of deception.

> revealed a widespread pattern of manipulative behaviour and abuse of power by an ideologically aligned group of Croatian language Wikipedia (Hr.WP) admins and other volunteer editors.

editors banned in 2020

> It lasted more than ten years and has led to the departure of editors upholding the five pillars and profound distortion of content in hundreds of articles and across different topics. Project capture of Croatian language Wikipedia has exposed – and exploited – a weakness in Wikipedia’s model of community self-governance. (this case) has demonstrated that both community and content can and will decline if institutions are taken over by an organised and ideologically aligned group.

project capture, radical right grouping, systematic obstruction of traditional community processes, mission misalignment

> this group consisted of real-life friends, ideological sympathisers and political allies
> The group has been using its on-wiki positions of power to attract new like-minded contributors, silence and ban dissenters, manipulate community elections and subvert Wikipedia’s and the broader movement’s native conflict resolution mechanisms.

> obstruction was the result of a well-organised effort by the same closely connected group. It further appears that the group intentionally deflected legitimate concerns about content bias and/or problematic behaviour by using well-known disinformation tactics, including relativisation of facts, whataboutism, discreditation of other participants and outright bullying. Contrary to what might have been expected, the group of misaligned Hr.WP admins actively participated in Meta RfC discussions.

> this evaluation has found that the quality of content on Hr.WP degraded progressively between 2013 and 2019, with more revisionist claims and disinformation inserted in an increasing number of articles each year.

> The experience of Croatian language Wikipedia raises important questions regarding global governance risks. It challenges the widely held view that all of Wikipedia is fairly and uniformly resilient in withstanding organised disinformation campaigns aiming to capture its language versions.

> Generally, the existing academic research into attempts at mounting organised disinformation campaigns on Wikipedia has primarily focused on detecting edits' frequency and filtering out suspicious editors
> (our niche)

> The lessons from Hr.WP pave the way for active community monitoring.

> Fresh calls for more institutional scrutiny of [other platforms hosting user-generated content] other platforms now come from established democracies trying to design an appropriate response to a string of coordinated disinformation campaigns that destabilised their election processes and undermined civil society.

> Seen by many governments as accomplices – if not outright enablers – of disinformation operations, major social media platforms will likely become the main targets of new regulatory legislation.

> The case of Croatian language Wikipedia demonstrates that there could be similar attempts of project capture in other languages as well.
> (global risk)

> A more resourced and better-organized attempt could be harder to detect and eventually reverse.

> Comparative analysis of the content published on the Croatian language Wikipedia against other language projects (...) revealed numerous examples of systemic, deeply-rooted bias and disinformation

> The analysis (...) confirmed that they had for years contained pervasive ideological bias.

Biases:

- Framing ("Also known as emulated neutrality. Giving equal weight to a range of competing claims, presenting questionable claims side by side with factual truths, or contextualising facts in a way that misleads readers.")
- source ("Citing non-neutral sources without disclosing their affiliation and/or providing dubious sources to back up claims presented in the article." framing bias often relies on it)
- selection ("Selectively including and excluding content regardless of its notability or topical relevance")

> Identifying disinformation, which usually entails demonstrating intent, on Wikipedia as such is substantially more difficult.

> In larger language Wikipedia projects, like English, Spanish, French or German, this diversity comes from the sheer number of participants, but also from the fact that these are all pluricentric languages with substantial numbers of native speakers coming from different countries, bringing somewhat different socio-political and cultural frames of reference to the well-established editorial peer on-wiki processes.
> (PL more at risk)
