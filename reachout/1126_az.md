# AZ

## co zrobiłem

### lokalny dewelopment

- Infra gotowa w/ ollama - lokalny model Llama 3.2 3B stoi, umie wypluwać rzeczy do bazy danych;

- wejście w rewizje polsko-ukraińskie

### wikipedia research

- Potwierdzenie potrzeby - duży wgląd w MLową infrę Wikipedii, potwierdzenie sensowności stworzenia "czulszego" narzędzia;

- reachout - Piotr Przybyła, PhD (Uni Pompeu Fabra) dał ważny feedback

- "klasyczna" analiza ilościowa - czy da się zaobserwować wzmorzony ruch w edycjach w pewnej grupie powiązanych z PL / UA artykułów?

### problemy z oryginalnym projektem

- detekcja intencji "klasycznie trudna"
- brak benchmarku, ORES działa inaczej niż myślałem
- datasety po polsku - brak granularnych, npov-related. produkcja własnego - odradzona (experci dziedzinowi, pare tysięcy olabelowaych przykładów, najlepiej dwóch annotatorów, najlepiej - biegłych w ukraińskim)
- llmy klasycznie słabe w to zadanie (~61%)

## pivot

- uleszenie detekcji LLM - są papery które skupione na "neutralizacji", gdzie część "detekcyjna" dot. subiektywności ma się słąbo. Propozycje autorów
- dla angielskiego istnieje dataset (WNC, potem WikiBias), pozwalający benchmarkować

👉🏼 model "heat-mapujący" artykuły jeśli chodzi o prawdopodobieństwo zmian;

👉🏼 zbenchmarkowanie modeli głównie anglo-języcznych (LLama / ChatGPT) i polskich (PLLuM / Bielik) na zadaniach związanych z SA / NER / stance detection;

👉🏼 analiza komparatywna "trudnych" tematów UA <-> PL z użyciem bardziej tradycyjnych narzędzi NLP - SA, NER, lub network analysis - Temporal Networks czy jeszcze innych, jak "informational gaps" i szeregi czasowe, supplementowane np porównaniem zmian, które zostały zrevertowanych i nie (np czy wprowadzili je zalogowani użytkownicy czy nie) itd.;

## notatki
