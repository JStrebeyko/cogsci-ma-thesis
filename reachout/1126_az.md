# AZ

## co zrobiem

### lokalny dewelopment

- Infra gotowa w/ ollama - lokalny model Llama 3.2 3B stoi, umie wypluwa rzeczy do bazy danych;

- wejcie w rewizje polsko-ukraiskie

### wikipedia research

- Potwierdzenie potrzeby - du偶y wgld w MLow infr Wikipedii, potwierdzenie sensownoci stworzenia "czulszego" narzdzia;

- reachout - Piotr Przybya, PhD (Uni Pompeu Fabra) da wa偶ny feedback

- "klasyczna" analiza ilociowa - czy da si zaobserwowa wzmorzony ruch w edycjach w pewnej grupie powizanych z PL / UA artyku贸w?

### problemy z oryginalnym projektem

- detekcja intencji "klasycznie trudna"
- brak benchmarku, ORES dziaa inaczej ni偶 mylaem
- datasety po polsku - brak granularnych, npov-related. produkcja wasnego - odradzona (experci dziedzinowi, pare tysicy olabelowaych przykad贸w, najlepiej dw贸ch annotator贸w, najlepiej - biegych w ukraiskim)
- llmy klasycznie sabe w to zadanie (~61%)

## pivot

- uleszenie detekcji LLM - s papery kt贸re skupione na "neutralizacji", gdzie cz "detekcyjna" dot. subiektywnoci ma si sbo. Propozycje autor贸w
- dla angielskiego istnieje dataset (WNC, potem WikiBias), pozwalajcy benchmarkowa

 model "heat-mapujcy" artykuy jeli chodzi o prawdopodobiestwo zmian;

 zbenchmarkowanie modeli g贸wnie anglo-jzycznych (LLama / ChatGPT) i polskich (PLLuM / Bielik) na zadaniach zwizanych z SA / NER / stance detection;

 analiza komparatywna "trudnych" temat贸w UA <-> PL z u偶yciem bardziej tradycyjnych narzdzi NLP - SA, NER, lub network analysis - Temporal Networks czy jeszcze innych, jak "informational gaps" i szeregi czasowe, supplementowane np por贸wnaniem zmian, kt贸re zostay zrevertowanych i nie (np czy wprowadzili je zalogowani u偶ytkownicy czy nie) itd.;

## notatki
