# AZ

## co zrobiÅ‚em

### lokalny dewelopment

- Infra gotowa w/ ollama - lokalny model Llama 3.2 3B stoi, umie wypluwaÄ‡ rzeczy do bazy danych;

- wejÅ›cie w rewizje polsko-ukraiÅ„skie

### wikipedia research

- Potwierdzenie potrzeby - duÅ¼y wglÄ…d w MLowÄ… infrÄ™ Wikipedii, potwierdzenie sensownoÅ›ci stworzenia "czulszego" narzÄ™dzia;

- reachout - Piotr PrzybyÅ‚a, PhD (Uni Pompeu Fabra) daÅ‚ waÅ¼ny feedback

- "klasyczna" analiza iloÅ›ciowa - czy da siÄ™ zaobserwowaÄ‡ wzmorzony ruch w edycjach w pewnej grupie powiÄ…zanych z PL / UA artykuÅ‚Ã³w?

### problemy z oryginalnym projektem

- detekcja intencji "klasycznie trudna"
- brak benchmarku, ORES dziaÅ‚a inaczej niÅ¼ myÅ›laÅ‚em
- datasety po polsku - brak granularnych, npov-related. produkcja wÅ‚asnego - odradzona (experci dziedzinowi, pare tysiÄ™cy olabelowaych przykÅ‚adÃ³w, najlepiej dwÃ³ch annotatorÃ³w, najlepiej - biegÅ‚ych w ukraiÅ„skim)
- llmy klasycznie sÅ‚abe w to zadanie (~61%)

## pivot

- uleszenie detekcji LLM - sÄ… papery ktÃ³re skupione na "neutralizacji", gdzie czÄ™Å›Ä‡ "detekcyjna" dot. subiektywnoÅ›ci ma siÄ™ sÅ‚Ä…bo. Propozycje autorÃ³w
- dla angielskiego istnieje dataset (WNC, potem WikiBias), pozwalajÄ…cy benchmarkowaÄ‡

ğŸ‘‰ğŸ¼ model "heat-mapujÄ…cy" artykuÅ‚y jeÅ›li chodzi o prawdopodobieÅ„stwo zmian;

ğŸ‘‰ğŸ¼ zbenchmarkowanie modeli gÅ‚Ã³wnie anglo-jÄ™zycznych (LLama / ChatGPT) i polskich (PLLuM / Bielik) na zadaniach zwiÄ…zanych z SA / NER / stance detection;

ğŸ‘‰ğŸ¼ analiza komparatywna "trudnych" tematÃ³w UA <-> PL z uÅ¼yciem bardziej tradycyjnych narzÄ™dzi NLP - SA, NER, lub network analysis - Temporal Networks czy jeszcze innych, jak "informational gaps" i szeregi czasowe, supplementowane np porÃ³wnaniem zmian, ktÃ³re zostaÅ‚y zrevertowanych i nie (np czy wprowadzili je zalogowani uÅ¼ytkownicy czy nie) itd.;

## notatki

### PomysÅ‚ 1: Pivot

- szybko, ale nudne

### PomysÅ‚ 2: Wojny edycyjne

"co jest clue zmiany edycyjnej?" "czy to szczegÃ³Å‚", "czy to waÅ¼ne"
"jeÅ¼eli charakter edycji idzie w stronÄ™ detalu, moÅ¼e to ingerencja"

- weÅº jakiekolwiek edycje, zapytaÄ‡ "czym rÃ³Å¼ni siÄ™ ta edycja" - "jak to siÄ™ zmienia"? "na ile sens artykuÅ‚u siÄ™ zmienia?", "na ile sens artykuÅ‚u"
- robisz embeddingi, clastring //
- ogÃ³lny problem jest trudny, ale tutaj taki insight

### â­ PomysÅ‚ 3: pierwszy akapit wikipedii

- wpleÅ›Ä‡ elementy o chorwacji
- zaÅ‚oÅ¼enie: duÅ¼e walki o pierwszy akapit, sugeruje bardzo duÅ¼o
- jak pierwszy akapit siÄ™ rÃ³Å¼ni miÄ™dzy "dobrymi" a "zÅ‚ymi"?
- wymieÅ„ waÅ¼ne rÃ³Å¼nice faktograficzne miÄ™dzy pierwszym akapitem a skompresowanÄ… rÃ³znicÄ™. Czy jest jakaÅ› zaleÅ¼noÅ›Ä‡ miÄ™dzy osiÄ… / aliantami?

1. 100 postaci historycznych najbardziej znane (WWII)
2. weÅº NAJTAÅƒSZY MODEL (GPT 3.5) ewentualnie polskiego bielika, LLamÄ™
3. bierzesz pierwszy akapit, kaÅ¼esz faktograficznie skompresowaÄ‡ resztÄ™ (max 300 sÅ‚Ã³w), "podsumuj biogram bazujÄ…c wyÅ‚Ä…cznie na tekÅ›cie"
4. przesyÅ‚asz pierwszy akapit i skompresowany artykuÅ‚, pytasz: czym siÄ™ rÃ³Å¼niÄ…, ktÃ³re sÄ… zawarte, a ktÃ³re pominiÄ™te? Pozytywne / negatywne? w czterech punktach (do 300-sÅ‚Ã³w) wymieÅ„ co zawarte, co pominiÄ™te, "BAZUJÄ„C NA TEKSCIE"
5. embeddingi tych 4 punktÃ³w dla kaÅ¼dej z postaci
6. klastrujesz
7. czy w tej rÃ³Å¼nicy doboru faktÃ³w historiograficznych dla postaci da siÄ™ wyczuÄ‡ z ktÃ³rej strony pochodzÄ…?
   prosta klasyfikacja - ludzie osi i aliantÃ³w

na poczÄ…tek: churchill, roosvelt, stalin, hitler, hirohito
